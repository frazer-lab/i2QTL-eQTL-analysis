{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from subprocess import call\n",
    "import subprocess\n",
    "import glob\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import djPyi2 as DJ\n",
    "from djPyi2 import Common as CM\n",
    "from djPyi2 import mpltools\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import copy \n",
    "import pybedtools as pbt\n",
    "import ciepy\n",
    "import cardipspy as cpy\n",
    "import itertools\n",
    "import tempfile\n",
    "import six\n",
    "import networkx as nx\n",
    "import scipy.stats as stats\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "from mpl_toolkits.axes_grid1 import  make_axes_locatable\n",
    "import datetime\n",
    "import vapeplot\n",
    "from scipy.stats import mode\n",
    "dy_name = 'eqtl_enrichments'\n",
    "\n",
    "private_out = os.path.join(DJ.root, 'private_output', dy_name)\n",
    "if not os.path.exists(private_out):\n",
    "    DJ.makedir(private_out)\n",
    "\n",
    "import gc\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.vectors import FloatVector\n",
    "\n",
    "stats_r = importr('stats')\n",
    "\n",
    "# from rpy2.robjects.packages import importr\n",
    "utils = importr('utils')\n",
    "\n",
    "def add_bh_fdr(top, col):\n",
    "    top = top.copy()\n",
    "    p_vals = top[col].tolist()\n",
    "    p_adjust = stats_r.p_adjust(FloatVector(p_vals), method = 'fdr')\n",
    "    top['fdr_corrected_p'] = list(p_adjust)\n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def per_variant_vc_unique(df, col1, col2, id_col, overlapping_sets = True):\n",
    "    \"\"\" value counts that are mutually exclusive within first col T/F - second groupby groups-\n",
    "    optionally, make sure the T/F sets are mutually exclusive entirely\"\"\"\n",
    "    \n",
    "    in_cat = df[(df[col1] == True)][id_col].unique()\n",
    "    in_cat_sig = df[(df[col1] == True) & (df[col2] == True)][id_col].unique()\n",
    "    in_cat_ns = df[(df[col1] == True) & (df[col2] == False)][id_col].unique()\n",
    "    in_cat_ns = set(in_cat_ns).difference(in_cat_sig)\n",
    "    num_in_cat_sig = len(in_cat_sig)\n",
    "    num_in_cat_ns = len(in_cat_ns)\n",
    "    \n",
    "    if not overlapping_sets:\n",
    "        ## make sure the two sets are totally mutually exclusive\n",
    "        out_cat = df[(df[col1] == False)][id_col].unique()\n",
    "        # remove things in the category from things out of the category \n",
    "        out_cat = set(out_cat).difference(in_cat)\n",
    "        out_bin = df[(df[col1] == False) & (df[id_col].isin(out_cat))]\n",
    "    else:\n",
    "        out_cat = df[(df[col1] == False)][id_col].unique()\n",
    "        out_bin = df[(df[col1] == False)]\n",
    "        \n",
    "    out_cat_sig =  out_bin[(out_bin[col2] == True)][id_col].unique()\n",
    "    out_cat_ns =  out_bin[(out_bin[col2] == False)][id_col].unique()\n",
    "    out_cat_ns = set(out_cat_ns).difference(out_cat_sig)\n",
    "    num_out_cat_sig = len(out_cat_sig)\n",
    "    num_out_cat_ns = len(out_cat_ns)\n",
    "\n",
    "    v_in = [[num_in_cat_sig, num_in_cat_ns], [num_out_cat_sig, num_out_cat_ns]]\n",
    "    return v_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vc_to_or(vc, v = False):\n",
    "    def default_loc(df, a, b, default = 0):\n",
    "        try:\n",
    "            out = df.loc[a,b]\n",
    "            return out\n",
    "        except:\n",
    "            return default\n",
    "\n",
    "        \n",
    "    if not v:\n",
    "        \n",
    "        t_g1 = [default_loc(vc, True, True), default_loc(vc, True, False)]\n",
    "        f_g1 = [default_loc(vc, False, True), default_loc(vc, False, False)]\n",
    "        v = [t_g1, f_g1]\n",
    "    else:\n",
    "        v = vc\n",
    "\n",
    "    try:\n",
    "        odds_ratio, p_fisher = stats.fisher_exact(v, )\n",
    "    except:\n",
    "        odds_ratio, p_fisher = (np.NaN, np.NaN)\n",
    "    \n",
    "    \n",
    "    return v, odds_ratio, p_fisher\n",
    "\n",
    "def gather_odds_ratio_data(df, gb1, gb2, bool_col, gb2_bool = True, unique_col = False,\n",
    "                           overlapping_sets = False):\n",
    "    \n",
    "    gb1_cats = df[gb1].unique()\n",
    "    if gb2_bool: # if this column is a bool- and not categorical\n",
    "        data = []\n",
    "        if not unique_col:\n",
    "            vc = df.groupby((gb1, gb2))[bool_col].value_counts()\n",
    "            for c1 in gb1_cats:\n",
    "                tvc = vc.loc[c1]\n",
    "                v, odds_ratio, p_fisher = vc_to_or(tvc)\n",
    "                data.append([c1, gb2, v, odds_ratio, p_fisher])\n",
    "        else:\n",
    "            for c1 in gb1_cats:\n",
    "                tdf = df[df[gb1] == c1]\n",
    "                if tdf.shape[0] > 0:\n",
    "                    vc = per_variant_vc_unique(tdf, gb2, \n",
    "                                               bool_col, unique_col, \n",
    "                                               overlapping_sets= overlapping_sets)\n",
    "                    v, odds_ratio, p_fisher = vc_to_or(vc, v=True)\n",
    "                    data.append([c1, gb2, v, odds_ratio, p_fisher]) \n",
    "            \n",
    "        \n",
    "        df_out = pd.DataFrame(data, columns = [gb1, gb2, 'contingency', 'odds_ratio', \n",
    "                                           'p_fisher']).pipe(add_bh_fdr, 'p_fisher')    \n",
    "    else:\n",
    "        data = []\n",
    "        gb2_cats = df[gb2].unique()\n",
    "        for c2 in gb2_cats:\n",
    "            df['in_cat'] = (df[gb2] == c2)\n",
    "            if not unique_col:\n",
    "                vc = df.groupby((gb1, 'in_cat'))[bool_col].value_counts()     \n",
    "            for c1 in gb1_cats:\n",
    "                if unique_col:\n",
    "                    tdf = df[df[gb1] == c1]\n",
    "                    if tdf.shape[0] > 0:\n",
    "                        v_in = per_variant_vc_unique(tdf, 'in_cat', \n",
    "                                               bool_col, unique_col, overlapping_sets= overlapping_sets)\n",
    "                        \n",
    "                        v, odds_ratio, p_fisher = vc_to_or(v_in, v=True)\n",
    "                        data.append([c1, c2, v, odds_ratio, p_fisher])   \n",
    "                else:\n",
    "                    tvc = vc.loc[c1]\n",
    "                    v, odds_ratio, p_fisher = vc_to_or(tvc)\n",
    "                    data.append([c1, c2, v, odds_ratio, p_fisher])\n",
    "                    \n",
    "        df_out = pd.DataFrame(data, columns = [gb1, gb2, 'contingency', 'odds_ratio', \n",
    "                                           'p_fisher']).pipe(add_bh_fdr, 'p_fisher') \n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def annotate_tests_data(df, col = \"significant\"):\n",
    "    df = df.copy()\n",
    "    def safe_div(a, b):\n",
    "        try:\n",
    "            out = a/b\n",
    "        except:\n",
    "            out = np.NaN\n",
    "        return out\n",
    "            \n",
    "#     df['frac_non_{}_ol_feat'.format(col)] = df['{}_False'.format(col)].apply(lambda x: safe_div(x[1], x[0]))\n",
    "#     df['frac_{}_ol_feat'.format(col)] =  df['{}_True'.format(col)].apply(lambda x: safe_div(x[1], x[0]))\n",
    "    try:\n",
    "        df['-log10p_fisher'] = np.log10(df['p_fisher']) * -1\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        df['log_odds_ratio'] = np.log10(df['odds_ratio'])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        df['log2_odds_ratio'] = np.log2(df['odds_ratio'])\n",
    "    except:\n",
    "        pass\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    df['log2_odds_ratio_raw'] = df['log2_odds_ratio']\n",
    "    \n",
    "    \n",
    "    t_neg_inf = df.log2_odds_ratio == (-np.inf)\n",
    "    t_pos_inf = (df.log2_odds_ratio == (np.inf))\n",
    "    \n",
    "    exclude = t_neg_inf[t_neg_inf].index.tolist() + t_pos_inf[t_pos_inf].index.tolist()\n",
    "    if len(exclude) > 0:\n",
    "        inds_non_inf = set(df.index.tolist()).difference(exclude)\n",
    "\n",
    "        if t_neg_inf[t_neg_inf].shape[0] > 0:\n",
    "            inds = t_neg_inf[t_neg_inf].index.tolist()\n",
    "            try:\n",
    "                m = df.loc[inds_non_inf].log2_odds_ratio.min()\n",
    "            except:\n",
    "                m = -1\n",
    "            \n",
    "            if m >= -0.5:\n",
    "                m = -1\n",
    "            df.loc[inds, 'log2_odds_ratio'] = m\n",
    "            \n",
    "        if t_pos_inf[t_pos_inf].shape[0] > 0:\n",
    "            inds = t_pos_inf[t_pos_inf].index.tolist()\n",
    "            try:\n",
    "                m = df.loc[inds_non_inf].log2_odds_ratio.max()\n",
    "            except:\n",
    "                m = 2\n",
    "            if m < 0:\n",
    "                m = 2\n",
    "            df.loc[inds, 'log2_odds_ratio'] = m\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vc_unique_add_proportion(df, gb, col_unique):\n",
    "    \"\"\"groupby two categories, and count the number of unique elements in the third\n",
    "    and proportion of total unique elements\"\"\"\n",
    "    vc = df.groupby((gb[0], gb[1]))[col_unique].apply(lambda x: len(set(x))).to_frame('count').reset_index()\n",
    "    vc_tot = df.groupby(gb[0])[col_unique].apply(lambda x: len(set(x))).to_frame('total')\n",
    "    vc = vc[vc[gb[1]] == True]\n",
    "    vc = vc.set_index(gb[0])\n",
    "    vc = vc.join(vc_tot)\n",
    "    vc['fraction'] = vc['count'] / vc['total']\n",
    "    return vc\n",
    "\n",
    "def add_fraction(vc, col, col_bool, count_col = 'count'):\n",
    "    vc_tot = vc.groupby(col)[count_col].sum().to_frame('total')\n",
    "    vc = vc[vc[col_bool] == True]\n",
    "    vc = vc.set_index(col)\n",
    "    vc = vc.join(vc_tot)\n",
    "    vc['fraction'] = vc['count'] / vc['total']\n",
    "    return vc\n",
    "\n",
    "def vc_w_prop(df, gb_col, bool_col):\n",
    "    vc = df.groupby(gb_col)[bool_col].value_counts().to_frame('count')\n",
    "    vc_frac = df.groupby(gb_col)[bool_col].value_counts(normalize = True).to_frame('fraction')\n",
    "    vc = vc.join(vc_frac)\n",
    "    vc = vc.reset_index()\n",
    "    tot = vc.groupby(gb_col)['count'].sum().to_frame('total')\n",
    "    \n",
    "    vc = vc[vc[bool_col] == True] \n",
    "    \n",
    "    vc = vc.set_index(gb_col).join(tot)\n",
    "    vc = vc.reset_index()\n",
    "    return vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_coding_annot_per_var(per_var):\n",
    "    \n",
    "    coding_egenes = var_egene_nr[(var_egene_nr.coding == True) & \n",
    "                                 (var_egene_nr.significant)].groupby('NR_ID').feature_id.unique().apply(len)\n",
    "\n",
    "    ncoding_egenes = var_egene_nr[(var_egene_nr.coding == False) &\n",
    "                                  (var_egene_nr.significant)].groupby('NR_ID').feature_id.unique().apply(len)\n",
    "\n",
    "    coding_tested = var_egene_nr[(var_egene_nr.coding == True)].groupby('NR_ID').feature_id.unique().apply(len)\n",
    "    ncoding_tested = var_egene_nr[(var_egene_nr.coding == False)].groupby('NR_ID').feature_id.unique().apply(len)\n",
    "\n",
    "    coding_lead = var_egene_nr[(var_egene_nr.coding == True) & \n",
    "                               (var_egene_nr.top_hit_final_sig)].groupby('NR_ID').feature_id.unique().apply(len)\n",
    "    ncoding_lead = var_egene_nr[(var_egene_nr.coding == False) & \n",
    "                                (var_egene_nr.top_hit_final_sig)].groupby('NR_ID').feature_id.unique().apply(len)\n",
    "\n",
    "    # coding_tested = var_egene_nr[(var_egene_nr.coding == True)].groupby('NR_ID').feature_id.unique().apply(len)\n",
    "    # ncoding_tested = var_egene_nr[(var_egene_nr.coding == False)].groupby('NR_ID').feature_id.unique().apply(len)\n",
    "\n",
    "    per_var['num_coding_egenes_lead'] = coding_lead\n",
    "    per_var['num_noncoding_egenes_lead'] = ncoding_lead\n",
    "\n",
    "    var_egene_nr = var_egene[(var_egene.most_significant_nr)]\n",
    "\n",
    "    per_var['num_coding_egenes'] = coding_egenes\n",
    "    per_var['num_noncoding_egenes'] = ncoding_egenes\n",
    "\n",
    "    per_var['num_coding_tested'] = coding_tested\n",
    "    per_var['num_noncoding_tested'] = ncoding_tested\n",
    "\n",
    "    per_var = per_var.fillna(0)\n",
    "    return per_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_enrichment_vs_cat(df, comp_cat, comp_col, gb1, gb2, gb3, order_comp = False, **kwargs):\n",
    "    dfs = []\n",
    "    if order_comp:\n",
    "        cats = order_comp\n",
    "    else:\n",
    "        cats = df[comp_col].unique().tolist()\n",
    "        try: cats.remove(comp_cat) \n",
    "        except: pass\n",
    "    for b in cats:\n",
    "        tdf = df[df[comp_col].isin([comp_cat, b])]\n",
    "        tdf['in_cat'] = (tdf[comp_col] == b)\n",
    "        enr = gather_odds_ratio_data(tdf, gb1, gb2, gb3, **kwargs)\n",
    "        enr['category'] = b\n",
    "        enr['comp_category'] = comp_cat\n",
    "        dfs.append(enr)\n",
    "    enr = pd.concat(dfs).pipe(annotate_tests_data).pipe(add_bh_fdr, \n",
    "                                                              'p_fisher').pipe(add_fraction_contingency)\n",
    "    tdf = df\n",
    "    tdf['in_cat'] = (tdf[comp_col] == comp_cat)\n",
    "    df = gather_odds_ratio_data(tdf, gb1, gb2, gb3, **kwargs)\n",
    "    df['category'] = comp_cat\n",
    "    df['comp_category'] = \"others\"\n",
    "    df = df.pipe(annotate_tests_data).pipe(add_fraction_contingency)\n",
    "    enr = pd.concat([enr,df])\n",
    "    return enr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_svtype_cats(all_qtls_filt):\n",
    "    convert = {'STR':'STR', 'INDEL': 'INDEL', 'SNP': 'SNV', 'SNV': 'SNV', 'INDEL_DEL': 'INDEL', \n",
    "               'INDEL_INS': 'INDEL'}\n",
    "    all_qtls_filt['SVTYPE_SUPER'] = all_qtls_filt.SVTYPE_NR.apply(lambda x: convert.get(x, 'SV'))\n",
    "    convert = {'STR':'STR', 'INDEL': 'INDEL', 'SNP': 'SNV',\n",
    "               'ALU': 'MEI', 'LINE1': 'MEI', 'SVA':'MEI', 'rMEI':'MEI', \n",
    "          'DUP': 'CNV', 'DEL': 'CNV', 'mCNV': 'CNV', 'SNV': 'SNV', 'INDEL_INS': 'INDEL', 'INDEL_DEL': 'INDEL', \n",
    "              'INDEL': 'INDEL', 'SNP': \"SNV\"}\n",
    "    all_qtls_filt['SVTYPE_COLLAPSE'] = all_qtls_filt.SVTYPE_NR.apply(lambda x: convert.get(x, 'other SV'))\n",
    "    convert = {'LINE1':'MEI', 'SVA': 'MEI', 'ALU': 'MEI'}\n",
    "    all_qtls_filt['SVTYPE_NR_C'] = all_qtls_filt.SVTYPE_NR.apply(lambda x: convert.get(x,x))\n",
    "    convert = {'LINE1':'MEI', 'SVA': 'MEI', 'ALU': 'MEI', 'DUP': 'CNV', 'DEL': 'CNV', 'mCNV': 'CNV'}\n",
    "    all_qtls_filt['SVTYPE_NR_C2'] = all_qtls_filt.SVTYPE_NR.apply(lambda x: convert.get(x,x))\n",
    "    \n",
    "    return all_qtls_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_svtypes(info_all_rna, suff = '_all'):\n",
    "    svt_col = \"SVTYPE{}\".format(suff)\n",
    "    st_col = \"SUBTYPE{}\".format(suff)\n",
    "    \n",
    "    inds = info_all_rna[(info_all_rna[svt_col] == 'mCNV') & (info_all_rna[st_col] == 'DEL')].index.tolist()\n",
    "\n",
    "    inds_nr = info_all_rna[(info_all_rna[svt_col] == 'mCNV') & (info_all_rna[st_col] == 'DEL') & \n",
    "                           (info_all_rna.ID == info_all_rna.NR_ID)].index.tolist()\n",
    "    \n",
    "    info_all_rna.loc[inds_nr, \"SVTYPE_NR\"] = 'DEL'\n",
    "\n",
    "    info_all_rna.loc[inds, svt_col] = 'DEL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_fraction_contingency(df):\n",
    "    df['fraction'] = df['contingency'].apply(lambda x: x[0][0]/sum(x[0]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dy_name = 'qtl_results_01_17_v4'\n",
    "outdir = os.path.join(private_out, dy_name)\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "    DJ.makedir(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_egene = pd.read_pickle('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/eqtl_processing/qtl_results_01_17_v4/var_egene_annot_maf5_sv_only.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_egene = var_egene.pipe(add_svtype_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_egene_nr = var_egene[var_egene.most_significant_nr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inds = var_egene_nr[(var_egene_nr.coding == True) & (var_egene_nr.significant)].snp_id.unique()\n",
    "var_egene_nr['has_coding_assoc'] = var_egene_nr.snp_id.isin(inds) # any coding egene for this variant\n",
    "\n",
    "# num signif per gene (is there a bunch of significant in LD?)\n",
    "t = var_egene_nr[var_egene_nr.significant].groupby(\"feature_id\").size().to_frame('num_signif_w_egene')\n",
    "var_egene_nr = var_egene_nr.merge(t, right_index=True, left_on= 'feature_id', how = 'left')\n",
    "\n",
    "\n",
    "var_egene_nr_nc = var_egene_nr[(var_egene_nr.coding == False) & (var_egene_nr.genic_category_variant != 'intersects_promoter')]\n",
    "\n",
    "var_egene_nr_nc_nd = var_egene_nr[(var_egene_nr.coding == False) & (var_egene_nr.genic_category_variant != 'intersects_promoter') & (var_egene_nr.near_distal_loop == True)]\n",
    "\n",
    "inds = var_egene_nr_nc_nd[var_egene_nr_nc_nd.category_min == 'inside_distal'].index.tolist()\n",
    "var_egene_nr_nc_nd['min_dist_pc_anchor_mod'] = var_egene_nr_nc_nd.min_dist_pc_anchor\n",
    "var_egene_nr_nc_nd.loc[inds, 'min_dist_pc_anchor_mod'] = var_egene_nr_nc_nd.loc[inds, 'min_dist_pc_anchor_mod'] * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_egene_nr_nc_nd = pd.read_pickle('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/eqtl_enrichments/qtl_results_01_17_v4/var_egene_nr_nc_nd.pkl')\n",
      "var_egene_nr_nc_nd = pd.read_csv('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/eqtl_enrichments/qtl_results_01_17_v4/var_egene_nr_nc_nd.tsv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "CM.save_dataframe('var_egene_nr_nc_nd', var_egene_nr_nc_nd, outdir, print_vars_recorded_loc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_egene_nr = pd.read_pickle('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/eqtl_enrichments/qtl_results_01_17_v4/var_egene_nr.pkl')\n",
      "var_egene_nr = pd.read_csv('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/eqtl_enrichments/qtl_results_01_17_v4/var_egene_nr.tsv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "CM.save_dataframe('var_egene_nr', var_egene_nr, outdir, print_vars_recorded_loc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "per_variant_info = pd.read_pickle('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/evariant_loop_analysis/qtl_results_v4/per_variant_info_annot_update.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "per_variant_info = per_variant_info.pipe(add_svtype_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrichments Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### likelihood to be eQTL of variants in each class versus variants from all others\n",
    "enr_svtype_nr_c = gather_odds_ratio_data(per_variant_info, 'ALL_VARS', 'SVTYPE_NR_C', 'significant_association', gb2_bool=False).pipe(annotate_tests_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### likelihood to be eQTL of variants in each class versus STRs\n",
    "enr_svt_vs_str_nr_c = compute_enrichment_vs_cat(per_variant_info, 'STR', 'SVTYPE_NR_C', \n",
    "                                           'ALL_VARS', 'in_cat', 'significant_association')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enr_svt_vs_str_nr_c_th = compute_enrichment_vs_cat(per_variant_info, 'STR', 'SVTYPE_NR_C', \n",
    "                                           'ALL_VARS', 'in_cat', 'lead_association')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enr_svt_vs_str_nr_c = pd.read_pickle('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/eqtl_enrichments/qtl_results_01_17_v4/enr_svt_vs_str_nr_c.pkl')\n",
      "\n",
      "enr_svt_vs_str_nr_c_th = pd.read_pickle('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/eqtl_enrichments/qtl_results_01_17_v4/enr_svt_vs_str_nr_c_th.pkl')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CM.save_dataframe('enr_svt_vs_str_nr_c', enr_svt_vs_str_nr_c, outdir, print_only_pickle=True, \n",
    "                 print_vars_recorded_loc=False)\n",
    "CM.save_dataframe('enr_svt_vs_str_nr_c_th',enr_svt_vs_str_nr_c_th, \n",
    "                  outdir, print_only_pickle=True,print_vars_recorded_loc=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrichment Genic Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tdf = var_egene_nr[(var_egene_nr.top_hit_final_sig == True)]\n",
    "# print tdf.shape\n",
    "enr_dfs = []\n",
    "for cat in order_genic_cats_full:\n",
    "    for svt in order_vars_c:\n",
    "        \n",
    "        tdf['in_cat'] = (tdf['genic_category_collapsed'] == cat)\n",
    "        tdf['is_svt'] = (tdf['SVTYPE_NR_C'] == svt)\n",
    "    \n",
    "        enr = gather_odds_ratio_data(tdf,'ALL_VARS', 'is_svt', \n",
    "                                     'in_cat', gb2_bool=True).pipe(annotate_tests_data)\n",
    "        enr['category'] = cat\n",
    "        enr['SVTYPE'] = svt\n",
    "        enr_dfs.append(enr)\n",
    "\n",
    "enr_svt_genic_cat_lead_prop = pd.concat(enr_dfs).pipe(add_bh_fdr, 'p_fisher').pipe(annotate_tests_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrichments Looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = [-0.5,0.5, 1.5, 3, 6, 100]\n",
    "bin_labels = ['0', '1', '1-3', '3-6', '6+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "per_variant_info['bin_num_loops_to_unique_genes']  = pd.cut(per_variant_info.num_genes_tested_loop, \n",
    "                                                             bins = bins, labels= bin_labels,\n",
    "                                                             include_lowest=True).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enr_int_pc_pqtl_svt_lead = gather_odds_ratio_data(var_egene_nr_nc_nd, 'SVTYPE_NR_C', \n",
    "                                            'int_distal_pc_10kb', 'top_hit_final_sig', \n",
    "                       gb2_bool=False).pipe(annotate_tests_data).pipe(add_fraction_contingency)\n",
    "\n",
    "inds = enr_int_pc_pqtl_svt_lead[enr_int_pc_pqtl_svt_lead.int_distal_pc_10kb].index.tolist()\n",
    "enr_int_pc_pqtl_svt_lead.loc[inds] = enr_int_pc_pqtl_svt_lead.loc[inds].pipe(add_bh_fdr, 'p_fisher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/frazer01/home/djakubosky/software/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: RuntimeWarning: divide by zero encountered in log10\n"
     ]
    }
   ],
   "source": [
    "enr_int_pc_pqtl_svt = gather_odds_ratio_data(var_egene_nr_nc_nd, 'SVTYPE_NR_C', \n",
    "                                            'int_distal_pc_10kb', 'significant', \n",
    "                       gb2_bool=False).pipe(annotate_tests_data).pipe(add_fraction_contingency)\n",
    "\n",
    "inds = enr_int_pc_pqtl_svt[enr_int_pc_pqtl_svt.int_distal_pc_10kb].index.tolist()\n",
    "enr_int_pc_pqtl_svt.loc[inds] = enr_int_pc_pqtl_svt.loc[inds].pipe(add_bh_fdr, 'p_fisher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enr_int_pc_pqtl_svt_lead = pd.read_pickle('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/eqtl_enrichments/qtl_results_01_17_v4/enr_int_pc_pqtl_svt_lead.pkl')\n",
      "enr_int_pc_pqtl_svt_lead = pd.read_csv('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/eqtl_enrichments/qtl_results_01_17_v4/enr_int_pc_pqtl_svt_lead.tsv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "CM.save_dataframe('enr_int_pc_pqtl_svt_lead', enr_int_pc_pqtl_svt_lead, outdir, \n",
    "                  print_vars_recorded_loc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enr_int_pc_pqtl_svt = pd.read_pickle('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/eqtl_enrichments/qtl_results_01_17_v4/enr_int_pc_pqtl_svt.pkl')\n",
      "enr_int_pc_pqtl_svt = pd.read_csv('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/eqtl_enrichments/qtl_results_01_17_v4/enr_int_pc_pqtl_svt.tsv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "CM.save_dataframe('enr_int_pc_pqtl_svt', enr_int_pc_pqtl_svt, outdir, \n",
    "                  print_vars_recorded_loc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/frazer01/home/djakubosky/software/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: RuntimeWarning: divide by zero encountered in log10\n"
     ]
    }
   ],
   "source": [
    "enr_n_loops_nearby_all = gather_odds_ratio_data(per_variant_info, 'ALL_VARS', \n",
    "                                            'bin_num_loops_to_unique_genes', 'significant_association', \n",
    "                       gb2_bool=False).pipe(annotate_tests_data).pipe(add_fraction_contingency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enr_n_loops_nearby_all_th = gather_odds_ratio_data(per_variant_info, 'ALL_VARS', \n",
    "                                            'bin_num_loops_to_unique_genes', 'lead_association', \n",
    "                       gb2_bool=False).pipe(annotate_tests_data).pipe(add_fraction_contingency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_enrichment_vs_cat(df, comp_cat, comp_col, gb1, gb2, gb3, order_comp = False, **kwargs):\n",
    "    dfs = []\n",
    "    if order_comp:\n",
    "        cats = order_comp\n",
    "    else:\n",
    "        cats = df[comp_col].unique().tolist()\n",
    "        try: cats.remove(comp_cat) \n",
    "        except: pass\n",
    "    for b in cats:\n",
    "        tdf = df[df[comp_col].isin([comp_cat, b])]\n",
    "        tdf['in_cat'] = (tdf[comp_col] == b)\n",
    "        enr = gather_odds_ratio_data(tdf, gb1, gb2, gb3, **kwargs)\n",
    "        enr['category'] = b\n",
    "        enr['comp_category'] = comp_cat\n",
    "        dfs.append(enr)\n",
    "    enr = pd.concat(dfs).pipe(annotate_tests_data).pipe(add_bh_fdr, \n",
    "                                                              'p_fisher').pipe(add_fraction_contingency)\n",
    "    tdf = df\n",
    "    tdf['in_cat'] = (tdf[comp_col] == comp_cat)\n",
    "    df = gather_odds_ratio_data(tdf, gb1, gb2, gb3, **kwargs)\n",
    "    df['category'] = comp_cat\n",
    "    df['comp_category'] = \"others\"\n",
    "    df = df.pipe(annotate_tests_data).pipe(add_fraction_contingency)\n",
    "#     enr = enr.append(df)\n",
    "    enr = pd.concat([enr,df])\n",
    "    return enr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enr_vs_none_all_th = compute_enrichment_vs_cat(per_variant_info, '0', 'bin_num_loops_to_unique_genes', \n",
    "                                           'ALL_VARS', 'in_cat', 'lead_association')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/frazer01/home/djakubosky/software/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: RuntimeWarning: divide by zero encountered in log10\n"
     ]
    }
   ],
   "source": [
    "enr_vs_none_all = compute_enrichment_vs_cat(per_variant_info, '0', 'bin_num_loops_to_unique_genes', \n",
    "                                           'ALL_VARS', 'in_cat', 'significant_association')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enr_n_loops_nearby_all_th = pd.read_pickle('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/eqtl_enrichments/qtl_results_01_17_v4/enr_n_loops_nearby_all_th.pkl')\n",
      "\n",
      "enr_n_loops_nearby_all = pd.read_pickle('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/eqtl_enrichments/qtl_results_01_17_v4/enr_n_loops_nearby_all.pkl')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CM.save_dataframe('enr_n_loops_nearby_all_th', enr_vs_none_all_th, \n",
    "                  outdir, print_only_pickle=True,print_vars_recorded_loc=False)\n",
    "CM.save_dataframe('enr_n_loops_nearby_all', enr_vs_none_all, outdir, print_only_pickle=True, \n",
    "                 print_vars_recorded_loc=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
